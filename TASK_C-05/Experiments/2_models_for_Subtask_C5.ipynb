{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12363954,
          "sourceType": "datasetVersion",
          "datasetId": 7795397
        }
      ],
      "dockerImageVersionId": 31091,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-13T21:39:18.472226Z",
          "iopub.execute_input": "2025-07-13T21:39:18.472493Z",
          "iopub.status.idle": "2025-07-13T21:39:21.060075Z",
          "shell.execute_reply.started": "2025-07-13T21:39:18.472462Z",
          "shell.execute_reply": "2025-07-13T21:39:21.059277Z"
        },
        "id": "Ql0CPMxtU8qa",
        "outputId": "56f35c79-bce2-4488-8754-3cbc48ac563a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/taskc-5/schemaorg_train_types.txt\n/kaggle/input/taskc-5/schemaorg_train_pairs.json\n/kaggle/input/taskc-5/schemaorg_test_types.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy pandas tqdm scikit-learn imbalanced-learn xgboost \\\n",
        "  transformers accelerate sentence-transformers bitsandbytes openai sentencepiece\n",
        "!pip install -q xgboost\n",
        "!pip install unsloth"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-13T21:39:21.061557Z",
          "iopub.execute_input": "2025-07-13T21:39:21.061936Z",
          "iopub.status.idle": "2025-07-13T21:44:14.484061Z",
          "shell.execute_reply.started": "2025-07-13T21:39:21.061914Z",
          "shell.execute_reply": "2025-07-13T21:44:14.483056Z"
        },
        "id": "z7J4QmSLU8qf",
        "outputId": "4ae440a3-bb79-420f-809c-6f032ca7dadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting unsloth\n  Downloading unsloth-2025.7.3-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.7.4 (from unsloth)\n  Downloading unsloth_zoo-2025.7.4-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.1)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.26-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.52.4)\nRequirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.8.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.19.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (0.21.2)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.7.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.7.4->unsloth) (11.2.1)\nCollecting msgspec (from unsloth_zoo>=2025.7.4->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.7.3-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.19.1-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.7.4-py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.26-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, trl, xformers, unsloth_zoo, torchvision, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.5.147\n    Uninstalling nvidia-curand-cu12-10.3.5.147:\n      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 shtab-1.7.2 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 triton-3.3.1 trl-0.19.1 tyro-0.9.26 unsloth-2025.7.3 unsloth_zoo-2025.7.4 xformers-0.0.31.post1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Embeddings – SentenceTransformer (all-mpnet-base-v2)\n",
        "\n",
        "Hybrid Similarity Metric – Cosine similarity + Norm-based penalty\n",
        "\n",
        "Lexical Features – String overlap, prefix, suffix matching\n",
        "\n",
        "Base Classifier – XGBoost (gradient boosting)\n",
        "\n",
        "Negative Sampling – Domain-informed and random negative generation\n",
        "\n",
        "Data Balancing – SMOTE oversampling\n",
        "\n",
        "Candidate Generation – Top-K similar pairs based on hybrid similarity\n",
        "\n",
        "LLM Re-ranking – Using Quantized Mistral 7B (unsloth/mistral-7b-instruct-v0.3-bnb-4bit) for float scoring\n",
        "\n",
        "Meta-classifier – LogisticRegression to fuse XGBoost + similarity + LLM scores\n",
        "\n",
        "Final Validation – GPT-4o float scoring for top-ranked candidates"
      ],
      "metadata": {
        "id": "OiPqaZcfU8qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 = 0.0761904762\n",
        "import os, json, random, numpy as np, pandas as pd, torch\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import openai\n",
        "\n",
        "class BestTaxonomyClassifier:\n",
        "    def __init__(self):\n",
        "        if not torch.cuda.is_available():\n",
        "            print(\"⚠️ Warning: No GPU detected. LLM inference will likely fail or be extremely slow.\")\n",
        "\n",
        "        self.train_types_path = \"/kaggle/input/taskc-5/schemaorg_train_types.txt\"\n",
        "        self.train_pairs_path = \"/kaggle/input/taskc-5/schemaorg_train_pairs.json\"\n",
        "        self.test_types_path = \"/kaggle/input/taskc-5/schemaorg_test_types.txt\"\n",
        "\n",
        "        self.embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "        self.base_clf = XGBClassifier(n_estimators=200, max_depth=6, eval_metric=\"logloss\")\n",
        "        self.meta_clf = LogisticRegression(max_iter=500)\n",
        "\n",
        "        model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        self.top_k = 100\n",
        "        self.sim_threshold = 0.1\n",
        "        self.gpt_threshold = 0.5\n",
        "        self.max_gpt_calls = 5000\n",
        "\n",
        "    def hybrid_similarity(self, p, c):\n",
        "        cos_sim = np.dot(p, c) / (np.linalg.norm(p) * np.linalg.norm(c))\n",
        "        diff_norm = np.linalg.norm(p - c)\n",
        "        return cos_sim - 0.1 * diff_norm\n",
        "\n",
        "    def load_data(self):\n",
        "        self.train_types = open(self.train_types_path).read().splitlines()\n",
        "        self.test_types = open(self.test_types_path).read().splitlines()\n",
        "        self.train_pairs = json.load(open(self.train_pairs_path))\n",
        "\n",
        "    def compute_embeddings(self):\n",
        "        if os.path.exists(\"/kaggle/working/embeddings.npy\"):\n",
        "            self.embeddings = np.load(\"/kaggle/working/embeddings.npy\", allow_pickle=True).item()\n",
        "        else:\n",
        "            all_types = list(set(self.train_types + self.test_types))\n",
        "            embs = self.embedder.encode(all_types, show_progress_bar=True)\n",
        "            self.embeddings = dict(zip(all_types, embs))\n",
        "            np.save(\"/kaggle/working/embeddings.npy\", self.embeddings)\n",
        "\n",
        "    def lexical_features(self, p, c):\n",
        "        pl, cl = p.lower(), c.lower()\n",
        "        shared = len(set(pl.split()).intersection(set(cl.split())))\n",
        "        return [shared, int(cl.startswith(pl)), int(cl.endswith(pl))]\n",
        "\n",
        "    def gen_features(self, p, c):\n",
        "        pe, ce = self.embeddings[p], self.embeddings[c]\n",
        "        sim = self.hybrid_similarity(pe, ce)\n",
        "        return np.concatenate([pe, ce, pe - ce, pe * ce, [sim], self.lexical_features(p, c)])\n",
        "\n",
        "    def prepare_training(self):\n",
        "        pos = [(p['parent'], p['child'], 1) for p in self.train_pairs]\n",
        "        pos_set = {(p, c) for p, c, _ in pos}\n",
        "        all_cands = self.train_types + self.test_types\n",
        "        neg = []\n",
        "        for p, c, _ in pos:\n",
        "            sims = [self.hybrid_similarity(self.embeddings[c], self.embeddings[t]) for t in all_cands]\n",
        "            top5 = [all_cands[i] for i in np.argsort(sims)[-10:]]\n",
        "            for x in top5 + random.sample(all_cands, 5):\n",
        "                if (p, x) not in pos_set and p != x:\n",
        "                    neg.append((p, x, 0))\n",
        "        df = pd.DataFrame(pos + neg, columns=[\"p\", \"c\", \"y\"])\n",
        "        df[\"feat\"] = df.apply(lambda r: self.gen_features(r.p, r.c), axis=1)\n",
        "        X = np.vstack(df.feat)\n",
        "        y = df.y.values\n",
        "        Xs, ys = SMOTE().fit_resample(X, y)\n",
        "        return Xs, ys\n",
        "\n",
        "    def train(self):\n",
        "        X, y = self.prepare_training()\n",
        "        self.base_feature_size = X.shape[1]\n",
        "        self.base_clf.fit(X, y)\n",
        "\n",
        "    def candidate_generation(self):\n",
        "        cands = []\n",
        "        all_parents = self.train_types + self.test_types\n",
        "        for child in self.test_types:\n",
        "            if child not in self.embeddings:\n",
        "                continue\n",
        "            sims = []\n",
        "            for p in all_parents:\n",
        "                if p == child or p not in self.embeddings:\n",
        "                    continue\n",
        "                sim = self.hybrid_similarity(self.embeddings[child], self.embeddings[p])\n",
        "                sims.append((p, sim))\n",
        "            sims = sorted(sims, key=lambda x: -x[1])[:self.top_k]\n",
        "            for p, s in sims:\n",
        "                if s >= self.sim_threshold:\n",
        "                    cands.append((p, child, s))\n",
        "        return cands\n",
        "\n",
        "    def llm_score(self, prompts):\n",
        "        inputs = self.tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(self.model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=16,\n",
        "                do_sample=False\n",
        "            )\n",
        "        decoded = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        scores = []\n",
        "        for out in decoded:\n",
        "            try:\n",
        "                scores.append(float(out.strip().split()[0]))\n",
        "            except:\n",
        "                scores.append(0.0)\n",
        "        return scores\n",
        "\n",
        "\n",
        "    def gpt_score(self, p, c):\n",
        "        prompt = f\"On a scale 0–1, how likely is '{c}' a subtype of '{p}' in Schema.org? Just float.\"\n",
        "        try:\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=3\n",
        "            )\n",
        "            return float(resp.choices[0].message.content.strip())\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def rerank(self):\n",
        "        self.load_data()\n",
        "        self.compute_embeddings()\n",
        "        self.train()\n",
        "        cands = self.candidate_generation()\n",
        "\n",
        "        if not cands:\n",
        "            raise ValueError(\"❌ No candidates generated. Try lowering sim_threshold or increasing top_k.\")\n",
        "\n",
        "        feats = np.array([self.gen_features(p, c) for p, c, _ in cands])\n",
        "        if feats.shape[1] != self.base_feature_size:\n",
        "            raise ValueError(f\"❌ Feature shape mismatch: expected {self.base_feature_size}, got {feats.shape}\")\n",
        "\n",
        "        xgb_scores = self.base_clf.predict_proba(feats)[:, 1]\n",
        "        sim_scores = [s for _, _, s in cands]\n",
        "\n",
        "        filtered = [(p, c, s, xb) for (p, c, s), xb in zip(cands, xgb_scores) if xb > 0.3 and s > 0.2]\n",
        "        filtered = sorted(filtered, key=lambda x: -x[3])[:5000]\n",
        "\n",
        "        prompts = [f\"On a scale 0–1, how likely is '{c}' a SUBTYPE of '{p}' in Schema.org? Just output a float.\"\n",
        "                   for p, c, _, _ in filtered]\n",
        "        llm_scores = self.llm_score(prompts)\n",
        "\n",
        "        meta_X = [[xb, sim] + self.lexical_features(p, c) + [ls]\n",
        "                  for (p, c, sim, xb), ls in zip(filtered, llm_scores)]\n",
        "        y_meta = [int((p, c) in {(pr['parent'], pr['child']) for pr in self.train_pairs})\n",
        "                  for (p, c, _, _) in filtered]\n",
        "\n",
        "        self.meta_clf.fit(meta_X, y_meta)\n",
        "\n",
        "        final_preds = {}\n",
        "        for (p, c, sim, xb), ls in zip(filtered, llm_scores):\n",
        "            score = self.meta_clf.predict_proba([[xb, sim] + self.lexical_features(p, c) + [ls]])[0][1]\n",
        "            final_preds.setdefault(c, []).append((p, score))\n",
        "\n",
        "        output = []\n",
        "        gpt_calls = 0\n",
        "        for child, lst in final_preds.items():\n",
        "            lst = sorted(lst, key=lambda x: -x[1])[:10]\n",
        "            if gpt_calls < self.max_gpt_calls:\n",
        "                lst = [(p, self.gpt_score(p, child)) for p, _ in lst[:3]]\n",
        "                gpt_calls += len(lst)\n",
        "                lst = sorted(lst, key=lambda x: -x[1])\n",
        "            for p, _ in lst[:5]:\n",
        "                output.append({\"parent\": p, \"child\": child})\n",
        "\n",
        "        with open(\"/kaggle/working/submission_best1.json\", \"w\") as f:\n",
        "            json.dump(output, f, indent=2)\n",
        "        print(f\"✅ Final submission written: {len(output)} pairs\")\n",
        "        return output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "    model = BestTaxonomyClassifier()\n",
        "    model.rerank()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-10T16:44:21.107366Z",
          "iopub.execute_input": "2025-07-10T16:44:21.107694Z",
          "iopub.status.idle": "2025-07-10T16:55:52.506084Z",
          "shell.execute_reply.started": "2025-07-10T16:44:21.107638Z",
          "shell.execute_reply": "2025-07-10T16:55:52.505252Z"
        },
        "colab": {
          "referenced_widgets": [
            "e827aa15673c461bb902320a46a13385",
            "7332a3e2432e45b79d0cd726b52dce0d",
            "d23dcc83cc8049cc8197e255d35ddc1a",
            "5af28607bc3447c7bb386f316dadbeca",
            "d2a075b8dbb94a0f9354642462cf8dc1",
            "395d616383154c5ab3e37e471045c1e8",
            "bb0709c2c3f64647be16cddbaaaf249d",
            "9cfcabe775604aa9a670e136fe1db71e",
            "5ab18d036de148eb806cb7fa928560bd",
            "7da7b7127c464c91a1a479e614760ae0",
            "1d80177d9194425c80998843f2a1eeff",
            "bef7dce20fa94b9d8ee0435e22357412",
            "506d953b3344465bac6d22a58c0d8be5",
            "0f072829cc3043f1b127c84b60b2bc25",
            "a79afead74be4e4e9caa79c6e68e6676",
            "af1d706e1df34bd38e387872fc09eebd",
            "1eaed11079744acdb51cdfe149f4f58b",
            "9640e5667fb346799928a6f2fe3c8022",
            "172d310fa06d4840917770c9157097be"
          ]
        },
        "id": "NDti70-ZU8qk",
        "outputId": "b254c47a-56b6-4bfa-a364-528546333b08"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-07-10 16:44:39.630609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752165879.987545      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752165880.092700      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e827aa15673c461bb902320a46a13385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7332a3e2432e45b79d0cd726b52dce0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d23dcc83cc8049cc8197e255d35ddc1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5af28607bc3447c7bb386f316dadbeca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2a075b8dbb94a0f9354642462cf8dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "395d616383154c5ab3e37e471045c1e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb0709c2c3f64647be16cddbaaaf249d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cfcabe775604aa9a670e136fe1db71e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab18d036de148eb806cb7fa928560bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7da7b7127c464c91a1a479e614760ae0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d80177d9194425c80998843f2a1eeff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bef7dce20fa94b9d8ee0435e22357412"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "506d953b3344465bac6d22a58c0d8be5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f072829cc3043f1b127c84b60b2bc25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79afead74be4e4e9caa79c6e68e6676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af1d706e1df34bd38e387872fc09eebd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:222: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eaed11079744acdb51cdfe149f4f58b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9640e5667fb346799928a6f2fe3c8022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/28 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "172d310fa06d4840917770c9157097be"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ Final submission written: 529 pairs\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 = 0.0695569319\n",
        "from unsloth import FastLanguageModel\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from transformers import (\n",
        "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer,\n",
        "    DPRContextEncoder, DPRContextEncoderTokenizer,\n",
        "    pipeline\n",
        ")\n",
        "import openai\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class RAGTaxonomyClassifier:\n",
        "    def __init__(self):\n",
        "        self.train_types_path = \"/kaggle/input/taskc-5/schemaorg_train_types.txt\"\n",
        "        self.train_pairs_path = \"/kaggle/input/taskc-5/schemaorg_train_pairs.json\"\n",
        "        self.test_types_path = \"/kaggle/input/taskc-5/schemaorg_test_types.txt\"\n",
        "\n",
        "        self.embedder = SentenceTransformer('all-mpnet-base-v2')\n",
        "        self.classifier = MLPClassifier(hidden_layer_sizes=(512, 128), max_iter=500, early_stopping=True)\n",
        "\n",
        "        self.q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "        self.q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "        self.ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "        self.ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "\n",
        "        model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "        os.environ[\"HF_TOKEN\"] = \"hf_...\"\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name=model_name,\n",
        "            max_seq_length=2048,\n",
        "            dtype=None,\n",
        "            load_in_4bit=True,\n",
        "            token=os.environ[\"HF_TOKEN\"]\n",
        "        )\n",
        "        self.rag_llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\", pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        self.sim_threshold = 0.4\n",
        "        self.ml_threshold = 0.4\n",
        "        self.rag_threshold = (0.4, 0.7)\n",
        "        self.gpt_threshold = 0.6\n",
        "        self.top_k_parents = 20\n",
        "        self.max_validations = 1000\n",
        "\n",
        "        self.definitions = {}\n",
        "        self.rag_cache = {}\n",
        "        self.gpt_cache = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        with open(self.train_types_path, 'r') as f:\n",
        "            self.train_types = [line.strip() for line in f.readlines()]\n",
        "        with open(self.train_pairs_path, 'r') as f:\n",
        "            self.train_pairs = json.load(f)\n",
        "        with open(self.test_types_path, 'r') as f:\n",
        "            self.test_types = [line.strip() for line in f.readlines()]\n",
        "        print(f\"✅ Loaded {len(self.train_types)} train types, {len(self.test_types)} test types\")\n",
        "\n",
        "    def compute_embeddings(self):\n",
        "        all_types = list(set(self.train_types + self.test_types))\n",
        "        print(\"🔄 Computing embeddings...\")\n",
        "        embeddings = self.embedder.encode(all_types, show_progress_bar=True)\n",
        "        self.embeddings = dict(zip(all_types, embeddings))\n",
        "\n",
        "    def generate_features(self, parent, child):\n",
        "        p_emb, c_emb = self.embeddings[parent], self.embeddings[child]\n",
        "        cos_sim = cosine_similarity([p_emb], [c_emb])[0][0]\n",
        "        return np.hstack([p_emb, c_emb, p_emb - c_emb, p_emb * c_emb, [cos_sim]])\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        print(\"📦 Preparing training data with SMOTE...\")\n",
        "        positives = [{\"parent\": p['parent'], \"child\": p['child'], \"label\": 1} for p in self.train_pairs]\n",
        "        positive_set = {(p['parent'], p['child']) for p in self.train_pairs}\n",
        "        negatives = []\n",
        "\n",
        "        for p in tqdm(self.train_pairs, desc=\"Generating hard negatives\"):\n",
        "            parent = p['parent']\n",
        "            candidates = [t for t in self.train_types if t != p['child'] and t != parent and (parent, t) not in positive_set]\n",
        "            child_emb = self.embeddings[p['child']]\n",
        "            sims = cosine_similarity([child_emb], [self.embeddings[t] for t in candidates])[0]\n",
        "            hard_negatives = [candidates[i] for i in np.argsort(sims)[-5:]]\n",
        "            for neg in hard_negatives:\n",
        "                negatives.append({\"parent\": parent, \"child\": neg, \"label\": 0})\n",
        "\n",
        "        df = pd.DataFrame(positives + negatives)\n",
        "        df['features'] = df.apply(lambda r: self.generate_features(r['parent'], r['child']), axis=1)\n",
        "        X = np.vstack(df['features'])\n",
        "        y = df['label']\n",
        "        X, y = SMOTE().fit_resample(X, y)\n",
        "        return X, y\n",
        "\n",
        "    def train_model(self, X, y):\n",
        "        print(\"🎯 Training MLP classifier...\")\n",
        "        self.classifier.fit(X, y)\n",
        "\n",
        "    def generate_candidates(self):\n",
        "        print(\"🔍 Generating candidate (parent, child) pairs...\")\n",
        "        candidates = []\n",
        "        test_embs = np.array([self.embeddings[t] for t in self.test_types])\n",
        "        sim_matrix = cosine_similarity(test_embs)\n",
        "        np.fill_diagonal(sim_matrix, -1)\n",
        "\n",
        "        for i, child in enumerate(tqdm(self.test_types)):\n",
        "            for parent in self.train_types:\n",
        "                sim = cosine_similarity([self.embeddings[child]], [self.embeddings[parent]])[0][0]\n",
        "                if sim > self.sim_threshold:\n",
        "                    candidates.append((parent, child))\n",
        "            top_indices = np.argsort(sim_matrix[i])[-self.top_k_parents:]\n",
        "            for j in top_indices:\n",
        "                if sim_matrix[i][j] > self.sim_threshold:\n",
        "                    candidates.append((self.test_types[j], child))\n",
        "        return list(set(candidates))\n",
        "\n",
        "    def rag_validate(self, parent, child):\n",
        "        key = f\"{parent}::{child}\"\n",
        "        if key in self.rag_cache:\n",
        "            return self.rag_cache[key]\n",
        "        question = f\"Is {child} a subtype of {parent} in the schema.org taxonomy?\"\n",
        "        parent_def = self.definitions.get(parent, parent)\n",
        "        child_def = self.definitions.get(child, child)\n",
        "        prompt = f\"{question}\\nParent: {parent_def}\\nChild: {child_def}\\nAnswer 'true' or 'false':\"\n",
        "        try:\n",
        "            response = self.rag_llm(prompt, max_new_tokens=5, temperature=0.01)[0]['generated_text']\n",
        "            result = 'true' in response.lower()\n",
        "            self.rag_cache[key] = result\n",
        "            return result\n",
        "        except:\n",
        "            self.rag_cache[key] = False\n",
        "            return False\n",
        "\n",
        "    def gpt4o_score(self, parent, child):\n",
        "        key = f\"{parent}::{child}\"\n",
        "        if key in self.gpt_cache:\n",
        "            return self.gpt_cache[key]\n",
        "        prompt = f\"On a scale from 0 to 1, how likely is it that '{child}' is a subtype of '{parent}' in a web ontology like schema.org? Answer with only a float.\"\n",
        "        try:\n",
        "            openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            score = float(response['choices'][0]['message']['content'].strip())\n",
        "            self.gpt_cache[key] = score\n",
        "            return score\n",
        "        except:\n",
        "            self.gpt_cache[key] = 0.0\n",
        "            return 0.0\n",
        "\n",
        "    def generate_submission(self):\n",
        "        X, y = self.prepare_training_data()\n",
        "        self.train_model(X, y)\n",
        "        candidates = self.generate_candidates()\n",
        "        features = [self.generate_features(p, c) for p, c in candidates]\n",
        "        probas = self.classifier.predict_proba(features)[:, 1]\n",
        "\n",
        "        results = []\n",
        "        rag_calls = 0\n",
        "\n",
        "        print(f\"⚖️  Filtering candidate pairs with ML > {self.ml_threshold}\")\n",
        "        for (parent, child), prob in tqdm(zip(candidates, probas)):\n",
        "            if prob >= self.ml_threshold:\n",
        "                if self.rag_threshold[0] < prob < self.rag_threshold[1] and rag_calls < self.max_validations:\n",
        "                    if self.rag_validate(parent, child):\n",
        "                        rag_calls += 1\n",
        "                        if prob > 0.9:\n",
        "                            results.append({\"parent\": parent, \"child\": child})\n",
        "                        else:\n",
        "                            score = self.gpt4o_score(parent, child)\n",
        "                            if score >= self.gpt_threshold:\n",
        "                                results.append({\"parent\": parent, \"child\": child})\n",
        "                elif prob >= self.rag_threshold[1]:\n",
        "                    results.append({\"parent\": parent, \"child\": child})\n",
        "\n",
        "        with open(\"/kaggle/working/submission_final_rag.json\", \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"✅ Submission ready: {len(results)} parent-child pairs written\")\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        X, y = self.prepare_training_data()\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.train_model(X_train, y_train)\n",
        "        y_pred = self.classifier.predict(X_val)\n",
        "        print(\"\\n📊 Classification Report:\")\n",
        "        print(classification_report(y_val, y_pred, digits=4))\n",
        "        print(\"\\n📉 Confusion Matrix:\")\n",
        "        print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "    def run(self):\n",
        "        self.load_data()\n",
        "        self.compute_embeddings()\n",
        "        self.generate_submission()\n",
        "        self.evaluate_model()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "    classifier = RAGTaxonomyClassifier()\n",
        "    classifier.run()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-13T21:46:58.267854Z",
          "iopub.execute_input": "2025-07-13T21:46:58.268230Z",
          "iopub.status.idle": "2025-07-13T21:54:07.766077Z",
          "shell.execute_reply.started": "2025-07-13T21:46:58.268206Z",
          "shell.execute_reply": "2025-07-13T21:54:07.765206Z"
        },
        "colab": {
          "referenced_widgets": [
            "5fc85e62e8424c74a8cc359685fdb82c",
            "76a9e232f0c34d48ab7c2e80e870733a",
            "fe375bea6b5c4b7a9ec656d95a4d36ee",
            "6650288de36949d4b23c39289f96bb4d",
            "41f7da53dc44426abb4563b34de79b5f",
            "bba23a461bd84e68b0f8caf12a7955a2",
            "dd56e7a8aeb94681aff3b81f5b5c1c2a",
            "e74bafc54df743edac6853b4aee27d6f",
            "b9c4510f1ae8496d90498ec4248a27a7",
            "faf0711d62e8468f9fff331fd901ea5c",
            "2e54f5bf23f1479687d65852df49f949",
            "a5419b8dd05a4688902d9a9207ae7060",
            "863a6a38f7494cb8a9c7a59a3bf05e52",
            "c661229dcc5a4b2b97cebd0429cadc03",
            "96beb6f270054ce0943f56a386ce1cea",
            "b2c5232d177c43b4a39d5eeb7942d086",
            "b5f5b1cee5b94c40bc30252100b2fe45",
            "b7e65f98a6c74db498ee61d57fbce845",
            "e397e9ac51a64eceba8fbd436dce0c25",
            "92273ac84e634db7b9a3ba6d696853c5",
            "3a49813dbe074825866765843d749bff",
            "9cd6ffcc72c24d06b03fce5b98999ebe",
            "ac612b9775054fc3bd20de45979d71a5",
            "33b2a894c8904627a181d52a50431276",
            "16e467d3fbb64836bcfe6d6f7a6267f5",
            "b9f6061275af49e88426880c8e947a69",
            "fa96279ecc1f4ed98f84db785ddd5aa1",
            "eccf06ff77614378b51848d6b96a2024",
            "c5b973665c5240f9943f3b45aa594e47",
            "2945a900d50f44f4818145f858be7c13"
          ]
        },
        "id": "hz7QitelU8ql",
        "outputId": "c92f979e-c9e9-490c-b328-b9eb29fc6371"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2025-07-13 21:47:10.563225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752443230.880439      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752443230.974886      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fc85e62e8424c74a8cc359685fdb82c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76a9e232f0c34d48ab7c2e80e870733a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe375bea6b5c4b7a9ec656d95a4d36ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6650288de36949d4b23c39289f96bb4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41f7da53dc44426abb4563b34de79b5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba23a461bd84e68b0f8caf12a7955a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd56e7a8aeb94681aff3b81f5b5c1c2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e74bafc54df743edac6853b4aee27d6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9c4510f1ae8496d90498ec4248a27a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf0711d62e8468f9fff331fd901ea5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e54f5bf23f1479687d65852df49f949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5419b8dd05a4688902d9a9207ae7060"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "863a6a38f7494cb8a9c7a59a3bf05e52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c661229dcc5a4b2b97cebd0429cadc03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96beb6f270054ce0943f56a386ce1cea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2c5232d177c43b4a39d5eeb7942d086"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f5b1cee5b94c40bc30252100b2fe45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7e65f98a6c74db498ee61d57fbce845"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e397e9ac51a64eceba8fbd436dce0c25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92273ac84e634db7b9a3ba6d696853c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a49813dbe074825866765843d749bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cd6ffcc72c24d06b03fce5b98999ebe"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac612b9775054fc3bd20de45979d71a5"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "==((====))==  Unsloth 2025.7.3: Fast Mistral patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b2a894c8904627a181d52a50431276"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16e467d3fbb64836bcfe6d6f7a6267f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f6061275af49e88426880c8e947a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa96279ecc1f4ed98f84db785ddd5aa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eccf06ff77614378b51848d6b96a2024"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5b973665c5240f9943f3b45aa594e47"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ Loaded 692 train types, 359 test types\n🔄 Computing embeddings...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/28 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2945a900d50f44f4818145f858be7c13"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "📦 Preparing training data with SMOTE...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 359/359 [01:37<00:00,  3.70it/s]23 [00:01<00:00, 391.64it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "⚖️  Filtering candidate pairs with ML > 0.4\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "97it [00:05, 23.03it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n10440it [03:22, 51.45it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ Submission ready: 1788 parent-child pairs written\n📦 Preparing training data with SMOTE...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Generating hard negatives: 100%|██████████| 723/723 [00:01<00:00, 443.76it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "🎯 Training MLP classifier...\n\n📊 Classification Report:\n              precision    recall  f1-score   support\n\n           0     0.9781    0.9053    0.9403       739\n           1     0.9081    0.9788    0.9421       707\n\n    accuracy                         0.9412      1446\n   macro avg     0.9431    0.9420    0.9412      1446\nweighted avg     0.9439    0.9412    0.9412      1446\n\n\n📉 Confusion Matrix:\n[[669  70]\n [ 15 692]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "MOSL920CU8qm"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}